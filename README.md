# paper-notes
This repository includes some paper notes that I read myself




## Distributed ML
* Locally Differentially Private Distributed Deep Learning via Knowledge Distillation（2022) [\[paper\]](https://arxiv.org/abs/2202.02971) [\[note\]](./notes/1_Locally_Differentially_Private_Distributed_Deep_Learning_via_Knowledge_Distillation.pdf)
* Federated Model Distillation with Noise-Free Differential Privacy (2021) [\[paper\]](https://www.ijcai.org/proceedings/2021/0216.pdf) [\[note\]](./notes/2_Federated_Model_Distillation_with_Noise_Free_Differential_Privacy.pdf)



## Knowledge Distillation
* Locally Differentially Private Distributed Deep Learning via Knowledge Distillation（2022）[\[paper\]](https://arxiv.org/abs/2202.02971) [\[note\]](./notes/1_Locally_Differentially_Private_Distributed_Deep_Learning_via_Knowledge_Distillation.pdf)
* Federated Model Distillation with Noise-Free Differential Privacy (2021) [\[paper\]](https://www.ijcai.org/proceedings/2021/0216.pdf) [\[note\]](./notes/2_Federated_Model_Distillation_with_Noise_Free_Differential_Privacy.pdf)



## Differential Privacy (DP)
* Locally Differentially Private Distributed Deep Learning via Knowledge Distillation（2022）[\[paper\]](https://arxiv.org/abs/2202.02971) [\[note\]](./notes/1_Locally_Differentially_Private_Distributed_Deep_Learning_via_Knowledge_Distillation.pdf)
* Federated Model Distillation with Noise-Free Differential Privacy (2021) [\[paper\]](https://www.ijcai.org/proceedings/2021/0216.pdf) [\[note\]](./notes/2_Federated_Model_Distillation_with_Noise_Free_Differential_Privacy.pdf)


## Natural Language Processing (NLP)



## For fun
